{"version":"1","records":[{"hierarchy":{"lvl1":"CMIP Cheatsheet"},"type":"lvl1","url":"/cmip-cheatsheet","position":0},{"hierarchy":{"lvl1":"CMIP Cheatsheet"},"content":"","type":"content","url":"/cmip-cheatsheet","position":1},{"hierarchy":{"lvl1":"CMIP Cheatsheet","lvl2":"For better understanding of CMIP go through the page below:"},"type":"lvl2","url":"/cmip-cheatsheet#for-better-understanding-of-cmip-go-through-the-page-below","position":2},{"hierarchy":{"lvl1":"CMIP Cheatsheet","lvl2":"For better understanding of CMIP go through the page below:"},"content":"","type":"content","url":"/cmip-cheatsheet#for-better-understanding-of-cmip-go-through-the-page-below","position":3},{"hierarchy":{"lvl1":"CMIP Cheatsheet","lvl2":"CMIP Github repositories:"},"type":"lvl2","url":"/cmip-cheatsheet#cmip-github-repositories","position":4},{"hierarchy":{"lvl1":"CMIP Cheatsheet","lvl2":"CMIP Github repositories:"},"content":"https://‚Äãgithub‚Äã.com‚Äã/WCRP‚Äã-CMIP","type":"content","url":"/cmip-cheatsheet#cmip-github-repositories","position":5},{"hierarchy":{"lvl1":"Cookbooks"},"type":"lvl1","url":"/cookbooks","position":0},{"hierarchy":{"lvl1":"Cookbooks"},"content":"","type":"content","url":"/cookbooks","position":1},{"hierarchy":{"lvl1":"Debuggers Guide"},"type":"lvl1","url":"/debugging","position":0},{"hierarchy":{"lvl1":"Debuggers Guide"},"content":"","type":"content","url":"/debugging","position":1},{"hierarchy":{"lvl1":"Debuggers Guide"},"type":"lvl1","url":"/debugging#debuggers-guide","position":2},{"hierarchy":{"lvl1":"Debuggers Guide"},"content":"","type":"content","url":"/debugging#debuggers-guide","position":3},{"hierarchy":{"lvl1":"Developers Guide"},"type":"lvl1","url":"/developer-guide","position":0},{"hierarchy":{"lvl1":"Developers Guide"},"content":"","type":"content","url":"/developer-guide","position":1},{"hierarchy":{"lvl1":"Developers Guide"},"type":"lvl1","url":"/developer-guide#developers-guide","position":2},{"hierarchy":{"lvl1":"Developers Guide"},"content":"","type":"content","url":"/developer-guide#developers-guide","position":3},{"hierarchy":{"lvl1":"What is ESG Publisher?"},"type":"lvl1","url":"/esg-publisher","position":0},{"hierarchy":{"lvl1":"What is ESG Publisher?"},"content":"","type":"content","url":"/esg-publisher","position":1},{"hierarchy":{"lvl1":"What is ESG Pull?"},"type":"lvl1","url":"/esg-pull","position":0},{"hierarchy":{"lvl1":"What is ESG Pull?"},"content":"","type":"content","url":"/esg-pull","position":1},{"hierarchy":{"lvl1":"ESG Voc"},"type":"lvl1","url":"/esg-voc","position":0},{"hierarchy":{"lvl1":"ESG Voc"},"content":"","type":"content","url":"/esg-voc","position":1},{"hierarchy":{"lvl1":"ESGF-Compute Guide"},"type":"lvl1","url":"/esgf-compute","position":0},{"hierarchy":{"lvl1":"ESGF-Compute Guide"},"content":"","type":"content","url":"/esgf-compute","position":1},{"hierarchy":{"lvl1":"ESGF-Compute Guide"},"type":"lvl1","url":"/esgf-compute#esgf-compute-guide","position":2},{"hierarchy":{"lvl1":"ESGF-Compute Guide"},"content":"","type":"content","url":"/esgf-compute#esgf-compute-guide","position":3},{"hierarchy":{"lvl1":"ESGF Docker Guide"},"type":"lvl1","url":"/esgf-docker","position":0},{"hierarchy":{"lvl1":"ESGF Docker Guide"},"content":"","type":"content","url":"/esgf-docker","position":1},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl2":"esgf-docker"},"type":"lvl2","url":"/esgf-docker#esgf-docker","position":2},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl2":"esgf-docker"},"content":"This repository contains the Dockerfiles and associated deployment artifacts for building\nand running the ESGF stack as Docker images.\n\nImages are built automatically for every commit that modifies the images directory and pushed\nto Docker Hub under the \n\nesgfdeploy organisation.\n\nThe ESGF stack can be deployed in one of two ways:\n\nUsing Ansible to deploy and configure containers on specific hosts\n\nUsing Helm to deploy containers to a Kubernetes cluster\n\nThe Kubernetes deployment is recommended if possible, but we recognise that not all sites will\nbe comfortable configuring and maintaining a Kubernetes cluster. However Ansible-based deployments\nwill not benefit from many features provided by Kubernetes, including:\n\nZero downtime upgrades\n\nHealth checks providing increased resilience\n\nAutomatic scaling and load-balancing\n\nAggregated logging and metrics","type":"content","url":"/esgf-docker#esgf-docker","position":3},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Current status","lvl2":"esgf-docker"},"type":"lvl3","url":"/esgf-docker#current-status","position":4},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Current status","lvl2":"esgf-docker"},"content":"This project is under heavy active development, with the implementation depending on the ESGF\nFuture Architecture discussions.\n\nCurrently, data and index nodes are implemented but without authentication.\n\nThe data node uses THREDDS to serve catalog and OPeNDAP endpoints, but uses Nginx for direct file\nserving which should be more performant than THREDDS.\n\nThe data node is capable of using existing catalogs from the current publisher to specify the\navailable data, however it is designed primarily to use a catalog-free configuration which utilises\n\n\ndatasetScan elements,\nto serve all files under a given dataset root. This will work with the next-generation publisher\nbeing developed at LLNL that does not rely on THREDDS catalogs for publishing metadata.","type":"content","url":"/esgf-docker#current-status","position":5},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Image tags","lvl2":"esgf-docker"},"type":"lvl3","url":"/esgf-docker#image-tags","position":6},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Image tags","lvl2":"esgf-docker"},"content":"Each image that is built for ESGF Docker is given several tags. Some of these are immutable, which\nmeans they refer to a fixed version of the image for all time, and some are mutable which means\nthat the underlying image will change over time.\n\nESGF Docker will apply the following tags when building images:\n\nMutable tags\n\nlatest: the latest build for the master branch\n\n<slugified-branch-name>: the latest build for the given branch name, as a slug, e.g.\nfor the branch issue/112/nginx-data-node use issue-112-nginx-data-node\n\nImmutable tags\n\nThe short Git hash for the commit that triggered the build, e.g. d65ca162, a031a2ca\n\nThe tag name for any tagged releases\n\nBy default, both the Ansible and Kubernetes installations use the latest tag when specifying\nDocker images, which is a mutable tag.\n\nFor production installations it is recommended to use an immutable tag, either for a tagged\nrelease or a particular commit, in order to avoid unexpected code changes or differences in\nthe container image between load-balanced nodes.\n\nYou can check the \n\navailable tags on Docker Hub.\nAll the ESGF Docker images are built together, so any given tag will be available for all images.","type":"content","url":"/esgf-docker#image-tags","position":7},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Making a deployment","lvl2":"esgf-docker"},"type":"lvl3","url":"/esgf-docker#making-a-deployment","position":8},{"hierarchy":{"lvl1":"ESGF Docker Guide","lvl3":"Making a deployment","lvl2":"esgf-docker"},"content":"Whether deploying ESGF using Kubernetes or Ansible, the first step is to clone the repository:git clone https://github.com/ESGF/esgf-docker.git\ncd esgf-docker\n\nThen follow the deployment guide for your chosen deployment method:\n\nDeploy ESGF using Ansible\n\nDeploy ESGF to Kubernetes using Helm","type":"content","url":"/esgf-docker#making-a-deployment","position":9},{"hierarchy":{"lvl1":"ESGF Installer"},"type":"lvl1","url":"/esgf-installer","position":0},{"hierarchy":{"lvl1":"ESGF Installer"},"content":"","type":"content","url":"/esgf-installer","position":1},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"New and returning installations"},"type":"lvl2","url":"/esgf-installer#new-and-returning-installations","position":2},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"New and returning installations"},"content":"Regardless of whether you have installed and administered an ESGF node previously, please read the following document on ESGF policies, as this should influence what type on installation you should do:\n\nhttp://‚Äãesgf‚Äã.llnl‚Äã.gov‚Äã/media‚Äã/pdf‚Äã/ESGF‚Äã-Policies‚Äã-and‚Äã-Guidelines‚Äã-V1‚Äã.0‚Äã.pdf","type":"content","url":"/esgf-installer#new-and-returning-installations","position":3},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"ESGF Docker Installation"},"type":"lvl2","url":"/esgf-installer#esgf-docker-installation","position":4},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"ESGF Docker Installation"},"content":"ESGF has adopted the use of containers for new node installations and upgrades, please see:\n\nhttps://‚Äãgithub‚Äã.com‚Äã/esgf‚Äã/esgf‚Äã-docker\n\nSpecific instructions for deployment methods are linked at the bottom of the README.","type":"content","url":"/esgf-installer#esgf-docker-installation","position":5},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"ESGF Ansible Installation - deprecated"},"type":"lvl2","url":"/esgf-installer#esgf-ansible-installation-deprecated","position":6},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"ESGF Ansible Installation - deprecated"},"content":"These Ansible playbooks are no longer being maintained.   Limited community support for the playbooks is possible, reach out to Tier-1 node administrators.\n\nThe prior ESGF installation procedure used \n\nAnsible.  Please see the following:\n\nESGF Ansible Documentation site\n\nESGF Ansible playbooks source repository\n\nInformation on the use of esgf-installer scripts are kept in this repository, though maintenance of these scripts have been discontinued on April 1, 2019.","type":"content","url":"/esgf-installer#esgf-ansible-installation-deprecated","position":7},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"esgf-installer - deprecated"},"type":"lvl2","url":"/esgf-installer#esgf-installer-deprecated","position":8},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"esgf-installer - deprecated"},"content":"The ESGF Installer is a command line tool for installing the ESGF Software Stack.The software stack is comprised of: Tomcat, Thredds, CDAT & CDMS, PostgreSQL, MyProxy, and several \n\nESGF.org custom software applications running on a LINUX (RedHat/CentOS) operating system.\n\nThe custom ESGF software includes:\n\nESGF-dashboard\n\nESGF-publisher\n\nESGF-node-manager\n\nESGF-stats-api\n\nESGF-search\n\nESGF-idp\n\nESGF-orp\n\nESGF-security\n\nESGF-SLCS-server","type":"content","url":"/esgf-installer#esgf-installer-deprecated","position":9},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Installation"},"type":"lvl2","url":"/esgf-installer#installation","position":10},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Installation"},"content":"To setup a ‚Äòdevel‚Äô installcd /usr/local/bin\nwget -O esg-bootstrap http://distrib-coffee.ipsl.jussieu.fr/pub/esgf/dist/devel/esgf-installer/2.5/esg-bootstrap --no-check-certificate  \nchmod 555 esg-bootstrap  \n./esg-bootstrap --devel   \n\nTo setup a ‚Äòmaster‚Äô installwget -O esg-bootstrap http://distrib-coffee.ipsl.jussieu.fr/pub/esgf/dist/esgf-installer/2.5/esg-bootstrap --no-check-certificate  \nchmod 555 esg-bootstrap  \n./esg-bootstrap\n\nMore detailed installation instructions can be found on the \n\nwiki","type":"content","url":"/esgf-installer#installation","position":11},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Support"},"type":"lvl2","url":"/esgf-installer#support","position":12},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Support"},"content":"Please \n\nopen an issue for support.\nPlease follow the \n\nIssue Tracking Guidelines when opening a new issue.","type":"content","url":"/esgf-installer#support","position":13},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Contributing"},"type":"lvl2","url":"/esgf-installer#contributing","position":14},{"hierarchy":{"lvl1":"ESGF Installer","lvl2":"Contributing"},"content":"Please contribute using \n\nGithub Flow. Create a branch, add commits, and \n\nopen a pull request.","type":"content","url":"/esgf-installer#contributing","position":15},{"hierarchy":{"lvl1":"What is intake-ESGF?"},"type":"lvl1","url":"/intake-esgf-1","position":0},{"hierarchy":{"lvl1":"What is intake-ESGF?"},"content":"","type":"content","url":"/intake-esgf-1","position":1},{"hierarchy":{"lvl1":"What is intake-ESGF?"},"type":"lvl1","url":"/intake-esgf-1","position":0},{"hierarchy":{"lvl1":"What is intake-ESGF?"},"content":"","type":"content","url":"/intake-esgf-1","position":1},{"hierarchy":{"lvl1":"Node Installation Guide"},"type":"lvl1","url":"/node-installation","position":0},{"hierarchy":{"lvl1":"Node Installation Guide"},"content":"","type":"content","url":"/node-installation","position":1},{"hierarchy":{"lvl1":"Node Installation Guide","lvl2":"Data node configuration"},"type":"lvl2","url":"/node-installation#data-node-configuration","position":2},{"hierarchy":{"lvl1":"Node Installation Guide","lvl2":"Data node configuration"},"content":"This section describes the most commonly used data node configuration options.\nFor a full list of available variables, please consult the chart at\n\n\nvalues.yaml. TOC depthFrom:2 \n\nConfiguring the available datasets\n\nFowarding access logs\n\nEnabling demand-based autoscaling\n\nUsing existing THREDDS catalogs\n\nImproving pod startup time for large catalogs /TOC ","type":"content","url":"/node-installation#data-node-configuration","position":3},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Configuring the available datasets","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#configuring-the-available-datasets","position":4},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Configuring the available datasets","lvl2":"Data node configuration"},"content":"By default, the data node uses a catalog-free configuration where the available data is defined simply by\na series of datasets. For each dataset, all files under the specified path will be served using both\nOPeNDAP (for NetCDF files) and plain HTTP. The browsable interface and OPeNDAP are provided by\nTHREDDS and direct file serving is provided by Nginx.\n\nThe configuration of the datasets is done using two variables:\n\ndata.mounts: List of volumes to mount into the container. Each item should contain the keys:\n\nmountPath: The path to mount the volume inside the container\n\nvolumeSpec: A \n\nKubernetes volume specification for\nthe volume containing the data\n\nname (optional): A name for the volume - by default, a name is derived from the mountPath\n\nmountOptions (optional): Options for the volume mount, e.g. mountPropagation for hostPath volumes\n\ndata.datasets: List of datasets to expose. Each item should contain the keys:\n\nname: The human-readable name of the dataset, displayed in the THREDDS UI\n\npath: The URL path part for the dataset\n\nlocation: The directory path to the root of the dataset in the container\n\nWarning\n\n\n\nWhen using hostPath volumes, the data must exist at the same path on all cluster nodes where the THREDDS\nor file server pods might be scheduled.\n\nIf your data is on a shared filesystem, just mount the filesystem on your cluster nodes as you would\nwith any other host.\n\nThese variables should be defined in your values.yaml, e.g.:data:\n  mounts:\n    # This uses a hostPath volume to mount /datacentre/archive on the host as /data in the container\n    - mountPath: /data\n      volumeSpec:\n        hostPath:\n          path: /datacentre/archive\n      mountOptions:\n        # mountPropagation is particularly important if the filesystem has automounted sub-mounts\n        mountPropagation: HostToContainer\n\n  datasets:\n    # This will expose files at /data/cmip6/[path] in the container\n    # as http://esgf-data.example.org/thredds/{dodsC,fileServer}/esg_cmip6/[path]\n    - name: CMIP6\n      path: esg_cmip6\n      location: /data/cmip6\n    # Similarly, this exposes files at /data/cordex/[path] in the container\n    # as http://esgf-data.example.org/thredds/{dodsC,fileServer}/esg_cordex/[path]\n    - name: CORDEX\n      path: esg_cordex\n      location: /data/cordex","type":"content","url":"/node-installation#configuring-the-available-datasets","position":5},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Using S3 buckets for data","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#using-s3-buckets-for-data","position":6},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Using S3 buckets for data","lvl2":"Data node configuration"},"content":"An S3 location for a dataset can be specified using s3Location instead of location in the yaml config, e.g.:  datasets:\n    - name: CMIP6\n      path: esg_cmip6\n      s3Location:\n        host: example.com\n        port: 443\n        bucket: bucket_name\n        dataPath: path/to/files\n\nWe don‚Äôt currently support adding security parameters for accessing secured S3 buckets.","type":"content","url":"/node-installation#using-s3-buckets-for-data","position":7},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Fowarding access logs","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#fowarding-access-logs","position":8},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Fowarding access logs","lvl2":"Data node configuration"},"content":"The THREDDS and Nginx file server components can be configured to forward access logs to\n\n\nCMCC for processing in order to produce download statistics for\nthe federation.\n\nBefore enabling this functionality you must first contact CMCC to arrange for the IP addresses\nof your Kubernetes nodes, as visible from the internet, to be whitelisted.\n\nIf your Kubernetes nodes are not directly exposed to the internet then they are probably using\n\n\nNetwork Address Translation (NAT)\nwhen accessing resources on the internet.\n\nIn this case, the address that you need to give to CMCC is the translated address.\n\nTo enable the forwarding of access logs for THREDDS and Nginx file server pods, add the following\nto your values.yaml:data:\n  accessLogSidecar:\n    enabled: true\n\nAdditional variables are available to configure the server to which logs should be forwarded,\nhowever the vast majority of deployments will not need to change these.","type":"content","url":"/node-installation#fowarding-access-logs","position":9},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Enabling demand-based autoscaling","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#enabling-demand-based-autoscaling","position":10},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Enabling demand-based autoscaling","lvl2":"Data node configuration"},"content":"Kubernetes allows the number of pods backing a service to be scaled up and down automatically using\na \n\nHorizontal Pod Autoscaler (HPA).\nThis allows the service to respond to spikes in demand by creating more pods to respond to requests.\nA Kubernetes Service ensures that requests are routed to the new replicas as they become ready.\n\nA HPA can be configured to automatically adjust the number of replicas based on any metrics that are exposed via\nthe \n\nMetrics API.\nBy default, this allows scaling based on the CPU or memory usage of the pods backing a service. However\nit is possible to integrate other metrics gathering systems, such as \n\nPrometheus,\nto allow scaling based on any of the collected metrics (e.g. network I/O, requests per second).\n\nBy default, autoscaling is disabled in the ESGF Helm chart. To enable autoscaling for the THREDDS and\nNginx file server components, the chart allows HorizontalPodAutoscaler resources to be defined using\nthe data.{thredds,fileServer}.hpa variables. These variables define the spec section of the HPA, except\nfor the scaleTargetRef section which is automatically populated with the correct reference.\nFor more information about HPA configuration, see the\n\n\nKubernetes HPA Walkthrough.\n\nWarning\n\n\n\nIn order to scale based on utilisation (as opposed to absolute value), you must define\nresources.requests for the service\n(see \n\nConfiguring container resources above).\n\nFor example, the following configuration would attempt to keep the average CPU utilisation\nbelow 80% of the requested amount by scaling out up to a maximum of 10 replicas:data:\n  thredds:\n    hpa:\n      minReplicas: 1\n      maxReplicas: 10\n      metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target:\n              type: Utilization\n              averageUtilization: 80\n\n  fileServer:\n    hpa:\n      minReplicas: 1\n      maxReplicas: 10\n      metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target:\n              type: Utilization\n              averageUtilization: 80","type":"content","url":"/node-installation#enabling-demand-based-autoscaling","position":11},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Using existing THREDDS catalogs","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#using-existing-thredds-catalogs","position":12},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Using existing THREDDS catalogs","lvl2":"Data node configuration"},"content":"The data node can be configured to serve data based on pre-existing THREDDS catalogs, for\nexample those generated by the ESGF publisher. To do this, you must specify the volume\ncontaining the catalogs using the variable data.thredds.catalogVolume. This volume must\nbe available to all nodes where THREDDS pods might be scheduled and must be able to be\nmounted in multiple pods at once, for example a hostPath using a shared filesystem.\nThis variable should contain the keys volumeSpec and mountOptions, which have the\nsame meaning as for data.mounts above, e.g.:data:\n  thredds:\n    catalogVolume:\n      volumeSpec:\n        hostPath:\n          path: /path/to/shared/catalogs\n      mountOptions:\n        mountPropagation: HostToContainer\n\nNote\n\n\n\nYou must still configure data.mounts and data.datasets as above, except in this case the\ndatasets should correspond the to the datasetRoots in your THREDDS catalogs.\n\nWhen the catalogs change, run the Helm chart in order to create new pods which will\nload the new catalogs. This will be done using a rolling upgrade with no downtime - the\nold pods will continue to serve requests with the old catalogs until new pods are ready.\n\nFor large catalogs, you may also need to adjust the startup time for the THREDDS container\nas THREDDS must build the catalog cache before it can start serving requests. To do this,\nspecify data.thredds.startTimeout, which specifies the number of seconds to wait for\nTHREDDS to start before assuming there is a problem and trying again (default 300):data:\n  thredds:\n    startTimeout: 3600  # Large catalogs may take an hour or more","type":"content","url":"/node-installation#using-existing-thredds-catalogs","position":13},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Improving pod startup time for large catalogs","lvl2":"Data node configuration"},"type":"lvl3","url":"/node-installation#improving-pod-startup-time-for-large-catalogs","position":14},{"hierarchy":{"lvl1":"Node Installation Guide","lvl3":"Improving pod startup time for large catalogs","lvl2":"Data node configuration"},"content":"Pods in Kubernetes are ephemeral, meaning they do not preserve state across restarts.\nThis includes the THREDDS caches, meaning that every time a pod starts it will spend time\nrebuilding the catalog cache before serving requests, even if the catalogs have not changed.\nThis is exacerbated by the fact that the catalogs will likely be on network-attached-storage\nin order to facilitate sharing across nodes, meaning higher latency for stat and read\noperations.\n\nFor large catalogs, this can result in THREDDS pods taking an hour or more to start. This is not\nmerely an inconvenience - in order to benefit from advanced features in Kubernetes such as\nrecovery from failure and demand-based autoscaling, pods must start quickly in order to begin\ntaking load as soon as possible. There are two things that can be done to address this problem:\n\nKeep a copy of the catalogs on the local disk of each node that may have THREDDS pods scheduled\n\nPre-build the catalog cache (again on the local disk of each node) and use it to seed the cache for new THREDDS pods\n\nIn an ESGF deployment, this is acheived by having a\n\n\nDaemonSet that runs on\neach node. When the Helm chart is run or a new node is added to the cluster, this DaemonSet\nwill syncronise the THREDDS catalogs to each node‚Äôs local disk and run THREDDS to build the catalog\ncache. The THREDDS pods will wait for the DaemonSet to finish updating the cache before starting,\nusing the pre-built cache as a seed for their own local caches. While they are waiting, the old\npods will continue to serve requests using the old catalogs, so the upgrade is zero-downtime.\nUsing this approach, copying the catalogs to local disk and rebuilding the cache are one-time\noperations and the THREDDS pods start much faster (less than one minute for a large catalog at\nCEDA in testing).\n\nTo enable local caching of catalogs for a deployment, just set data.thredds.localCache.enabled:data:\n  thredds:\n    localCache:\n      enabled: true","type":"content","url":"/node-installation#improving-pod-startup-time-for-large-catalogs","position":15},{"hierarchy":{"lvl1":"ESGF2-US"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"ESGF2-US"},"content":"\n\nWelcome to our the Earth System Grid Federation 2 - US (ESGF2-US) Project!\n\nI am looking for data üîé\n\nCheck out \n\nmetagrid, our search interface for finding ESGF Data!\n\nWhat is ESGF? üåê\n\nCheck out the \n\nESGF2-US Overview.\n\nI need examples üíª\n\nCheck out our \n\nESGF Computational Cookbook","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Back End?"},"type":"lvl1","url":"/backend","position":0},{"hierarchy":{"lvl1":"Back End?"},"content":"","type":"content","url":"/backend","position":1},{"hierarchy":{"lvl1":"Back End?"},"type":"lvl1","url":"/backend#back-end","position":2},{"hierarchy":{"lvl1":"Back End?"},"content":"","type":"content","url":"/backend#back-end","position":3},{"hierarchy":{"lvl1":"Data User Guide"},"type":"lvl1","url":"/data-users","position":0},{"hierarchy":{"lvl1":"Data User Guide"},"content":"","type":"content","url":"/data-users","position":1},{"hierarchy":{"lvl1":"Kubernetes Guide"},"type":"lvl1","url":"/kubernetes","position":0},{"hierarchy":{"lvl1":"Kubernetes Guide"},"content":"","type":"content","url":"/kubernetes","position":1},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl2":"Deploy ESGF using Kubernetes"},"type":"lvl2","url":"/kubernetes#deploy-esgf-using-kubernetes","position":2},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl2":"Deploy ESGF using Kubernetes"},"content":"This project provides a \n\nHelm chart to deploy ESGF resources\non a \n\nKubernetes cluster.\n\nThe chart is in \n\ndeploy‚Äã/kubernetes‚Äã/chart. Please look at the\nfiles to understand exactly what resources are being created.\n\nFor a complete list of all the variables that are available, please look at the\n\n\nvalues.yaml for the chart. The defaults there have\nextensive comments that explain how to use these variables. This documentation describes how to\napply some common configurations. TOC depthFrom:2 \n\nInstalling/upgrading ESGF\n\nLocal test installation with Minikube\n\nConfiguring the installation /TOC ","type":"content","url":"/kubernetes#deploy-esgf-using-kubernetes","position":3},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Installing/upgrading ESGF","lvl2":"Deploy ESGF using Kubernetes"},"type":"lvl3","url":"/kubernetes#installing-upgrading-esgf","position":4},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Installing/upgrading ESGF","lvl2":"Deploy ESGF using Kubernetes"},"content":"Before attempting to install the ESGF Helm chart, you must have the following:\n\nA Kubernetes cluster with an\n\n\nIngress Controller enabled\n\nkubectl installed and configured to talk\nto your cluster\n\nHelm installed\n\nNext, make a configuration directory - this can be anywhere on your machine that is not under\nesgf-docker. You can also place this directory under version control if you wish - this can be very\nuseful for tracking changes to the configuration, or even triggering deployments automatically when\nconfiguration changes.\n\nIn your configuration directory, make a new YAML file called values.yaml and override any variables to fit\nyour deployment. The only required variable is hostname, which should be the DNS name at which your\nESGF deployment will be available:hostname: esgf.example.org\n\nNote\n\n\n\nThe Helm chart does not create a DNS entry for the hostname. This must be separately configured\nto point to the ingress controller for your Kubernetes cluster.\n\nOnce you have configured your values.yaml, you can install or upgrade ESGF using the Helm chart. If no\nnamespace is specified, it will use the default namespace for your kubectl configuration:helm upgrade -i [-n <namespace>] -f /my/esgf/config/values.yaml --wait esgf ./deploy/kubernetes/chart","type":"content","url":"/kubernetes#installing-upgrading-esgf","position":5},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Local test installation with Minikube","lvl2":"Deploy ESGF using Kubernetes"},"type":"lvl3","url":"/kubernetes#local-test-installation-with-minikube","position":6},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Local test installation with Minikube","lvl2":"Deploy ESGF using Kubernetes"},"content":"For local test deployments, you can use \n\nMinikube\nwith data from \n\nroocs‚Äã/mini‚Äã-esgf‚Äã-data:# Start the minikube cluster\nminikube start\n# Enable the ingress addon\nminikube addons enable ingress\n# Install the test data\nminikube ssh \"curl -fsSL https://github.com/roocs/mini-esgf-data/tarball/master | sudo tar -xz --strip-components=1 -C / --wildcards */test_data\"\n\nConfigure the chart to serve the test data (see\n\n\nminikube‚Äã-values‚Äã.yaml), using a nip.io\ndomain pointing to the Minikube server:helm install esgf ./deploy/kubernetes/chart/ \\\n  -f ./deploy/kubernetes/minikube-values.yaml \\\n  --set hostname=\"$(minikube ip).nip.io\"\n\nOnce the containers have started, the THREDDS interface will be available at http://$(minikube ip).nip.io/thredds.","type":"content","url":"/kubernetes#local-test-installation-with-minikube","position":7},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Configuring the installation","lvl2":"Deploy ESGF using Kubernetes"},"type":"lvl3","url":"/kubernetes#configuring-the-installation","position":8},{"hierarchy":{"lvl1":"Kubernetes Guide","lvl3":"Configuring the installation","lvl2":"Deploy ESGF using Kubernetes"},"content":"See \n\nConfiguring a Kubernetes deployment.","type":"content","url":"/kubernetes#configuring-the-installation","position":9},{"hierarchy":{"lvl1":"Metagrid Guide"},"type":"lvl1","url":"/metagrid-guide-1","position":0},{"hierarchy":{"lvl1":"Metagrid Guide"},"content":"","type":"content","url":"/metagrid-guide-1","position":1},{"hierarchy":{"lvl1":"Metagrid Guide","lvl2":"Learn more about Datasets"},"type":"lvl2","url":"/metagrid-guide-1#learn-more-about-datasets","position":2},{"hierarchy":{"lvl1":"Metagrid Guide","lvl2":"Learn more about Datasets"},"content":"Well we all have a basic Idea of what ESGF is, if not please look at this  (https://intake-esgf.readthedocs.io/en/latest/)` for a better understanding.\n\nLets start with every possible question that a newbie like me would have.","type":"content","url":"/metagrid-guide-1#learn-more-about-datasets","position":3},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"What is Metagrid?","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#what-is-metagrid","position":4},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"What is Metagrid?","lvl2":"Learn more about Datasets"},"content":"MetaGrid is the next-generation search interface for the Earth System Grid Federation (ESGF). It‚Äôs a user-friendly web application designed to help researchers find and access climate model data stored within the ESGF. Think of it as a more advanced way to search for and retrieve the data needed for climate research.\n\nHere‚Äôs a more detailed breakdown:\n\nESGF‚Äôs Role:\nThe Earth System Grid Federation (ESGF) is a global network of data centers that provides access to climate model outputs. It‚Äôs a crucial resource for climate scientists, particularly for projects like the Intergovernmental Panel on Climate Change (IPCC) assessments.","type":"content","url":"/metagrid-guide-1#what-is-metagrid","position":5},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"MetaGrid‚Äôs Function:","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#metagrids-function","position":6},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"MetaGrid‚Äôs Function:","lvl2":"Learn more about Datasets"},"content":"MetaGrid is the tool that users interact with to search through the vast amount of data available through ESGF. It offers features like:\n\nFacet Value Free-Text Entry: Allows users to quickly find relevant options by typing instead of scrolling through long lists of facets (like model names, variables, etc.).\n\nSaved Searches: Users can save their search queries and reuse them later.\nShareable Result Links: Enables users to share specific search results with colleagues.\n\nHow it helps:\nMetaGrid simplifies the process of finding the specific climate data needed for research, making it easier to access and utilize the data available through ESGF.\n\nHere‚Äôs the link to Metagrid https://aims2.llnl.gov/","type":"content","url":"/metagrid-guide-1#metagrids-function","position":7},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"How do I use this interface?","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#how-do-i-use-this-interface","position":8},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"How do I use this interface?","lvl2":"Learn more about Datasets"},"content":"","type":"content","url":"/metagrid-guide-1#how-do-i-use-this-interface","position":9},{"hierarchy":{"lvl1":"Metagrid Guide"},"type":"lvl1","url":"/metagrid-guide-1","position":0},{"hierarchy":{"lvl1":"Metagrid Guide"},"content":"","type":"content","url":"/metagrid-guide-1","position":1},{"hierarchy":{"lvl1":"Metagrid Guide","lvl2":"Learn more about Datasets"},"type":"lvl2","url":"/metagrid-guide-1#learn-more-about-datasets","position":2},{"hierarchy":{"lvl1":"Metagrid Guide","lvl2":"Learn more about Datasets"},"content":"Well we all have a basic Idea of what ESGF is, if not please look at this  (https://intake-esgf.readthedocs.io/en/latest/)` for a better understanding.\n\nLets start with every possible question that a newbie like me would have.","type":"content","url":"/metagrid-guide-1#learn-more-about-datasets","position":3},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"What is Metagrid?","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#what-is-metagrid","position":4},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"What is Metagrid?","lvl2":"Learn more about Datasets"},"content":"MetaGrid is the next-generation search interface for the Earth System Grid Federation (ESGF). It‚Äôs a user-friendly web application designed to help researchers find and access climate model data stored within the ESGF. Think of it as a more advanced way to search for and retrieve the data needed for climate research.\n\nHere‚Äôs a more detailed breakdown:\n\nESGF‚Äôs Role:\nThe Earth System Grid Federation (ESGF) is a global network of data centers that provides access to climate model outputs. It‚Äôs a crucial resource for climate scientists, particularly for projects like the Intergovernmental Panel on Climate Change (IPCC) assessments.","type":"content","url":"/metagrid-guide-1#what-is-metagrid","position":5},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"MetaGrid‚Äôs Function:","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#metagrids-function","position":6},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"MetaGrid‚Äôs Function:","lvl2":"Learn more about Datasets"},"content":"MetaGrid is the tool that users interact with to search through the vast amount of data available through ESGF. It offers features like:\n\nFacet Value Free-Text Entry: Allows users to quickly find relevant options by typing instead of scrolling through long lists of facets (like model names, variables, etc.).\n\nSaved Searches: Users can save their search queries and reuse them later.\nShareable Result Links: Enables users to share specific search results with colleagues.\n\nHow it helps:\nMetaGrid simplifies the process of finding the specific climate data needed for research, making it easier to access and utilize the data available through ESGF.\n\nHere‚Äôs the link to Metagrid https://aims2.llnl.gov/","type":"content","url":"/metagrid-guide-1#metagrids-function","position":7},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"How do I use this interface?","lvl2":"Learn more about Datasets"},"type":"lvl3","url":"/metagrid-guide-1#how-do-i-use-this-interface","position":8},{"hierarchy":{"lvl1":"Metagrid Guide","lvl3":"How do I use this interface?","lvl2":"Learn more about Datasets"},"content":"","type":"content","url":"/metagrid-guide-1#how-do-i-use-this-interface","position":9},{"hierarchy":{"lvl1":"Replicators"},"type":"lvl1","url":"/replicator","position":0},{"hierarchy":{"lvl1":"Replicators"},"content":"","type":"content","url":"/replicator","position":1},{"hierarchy":{"lvl1":"Replicators","lvl2":"ESGF-NG Replicator"},"type":"lvl2","url":"/replicator#esgf-ng-replicator","position":2},{"hierarchy":{"lvl1":"Replicators","lvl2":"ESGF-NG Replicator"},"content":"The ESGF-NG Replicator is a service designed to be used by ESGF Data Node operators with the new \n\nESGF-NG core architecture.\n\nIt monitors the ESGF-wide Event Stream.\n\nWhen it sees a new ESGF dataset that matches a configured replication policy, it makes a replica of the dataset in configured local storage.\n\nIt updates the configured ESGF STAC Catalogue with information about any replicas it creates.\n\nThe design-docs folder contains the following:\n\nUser Stories\n\nRequirements\n\nKey Design Points, aka Technical Requirements\n\nOpen Questions","type":"content","url":"/replicator#esgf-ng-replicator","position":3}]}